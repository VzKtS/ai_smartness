# AI Smartness v5.2 - Auto-Optimization

**Version:** 5.2.0
**Status:** Specification
**Date:** 2026-02-02
**Author:** Claude (ai_smartness_dev) + KratOs feedback

## Overview

Version 5.2 focuses on **automatic memory optimization** to reduce manual intervention and improve context efficiency. These features are based on real-world feedback from the KratOs agent.

## Problem Statement

Current issues observed in production:
- Multiple threads with >90% similarity coexist (e.g., 3 GRANDPA threads)
- `context_pressure: 1.0` reached frequently
- Manual batch operations require N separate tool calls
- Old inactive threads keep their weight indefinitely

## Features

### 1. Auto-Merge for High Similarity

**Goal:** Automatically merge threads with very high similarity (>0.90) without manual intervention.

**Implementation:**
```python
# In daemon processor (periodic task)
def auto_merge_similar():
    candidates = find_similar_threads(threshold=0.90)
    for pair in candidates:
        if pair.similarity > AUTO_MERGE_THRESHOLD:
            merge(survivor=pair.higher_weight, absorbed=pair.lower_weight)
            log(f"AUTO-MERGE: {pair.absorbed} → {pair.survivor}")
```

**Configuration:**
```json
{
  "settings": {
    "auto_merge_threshold": 0.90,
    "auto_merge_enabled": true
  }
}
```

**Behavior:**
- Runs during daemon heartbeat cycle
- Keeps thread with higher weight as survivor
- Logs all auto-merges for audit
- Respects `split_locked` threads

---

### 2. Deduplication at Creation

**Goal:** Before creating a new thread, check if a similar one exists and enrich it instead.

**Implementation:**
```python
# In thread creation flow
def create_or_enrich_thread(content, topics):
    similar = find_similar_threads(content, threshold=0.85)

    if similar and similar[0].score > DEDUP_THRESHOLD:
        # Enrich existing thread
        existing = similar[0].thread
        existing.add_message(content)
        existing.merge_topics(topics)
        existing.boost_weight(0.1)
        return existing
    else:
        # Create new thread
        return create_thread(content, topics)
```

**Configuration:**
```json
{
  "settings": {
    "dedup_threshold": 0.85,
    "dedup_enabled": true
  }
}
```

---

### 3. Proactive Compression

**Goal:** Trigger automatic compaction when context pressure exceeds threshold.

**Implementation:**
```python
# In daemon heartbeat
def check_pressure():
    pressure = calculate_context_pressure()

    if pressure > PRESSURE_THRESHOLD:
        strategy = "aggressive" if pressure > 0.95 else "normal"
        compact(strategy=strategy)
        log(f"PROACTIVE-COMPACT: pressure={pressure}, strategy={strategy}")
```

**Configuration:**
```json
{
  "settings": {
    "proactive_compact_threshold": 0.80,
    "proactive_compact_enabled": true
  }
}
```

**Thresholds:**
- `> 0.80` → `normal` compaction
- `> 0.95` → `aggressive` compaction

---

### 4. Temporal Weight Decay

**Goal:** Old inactive threads naturally lose weight over time, freeing context.

**Formula:**
```python
def effective_weight(thread):
    age_days = (now - thread.last_active).days
    decay_factor = max(0.1, 1.0 - (age_days * DECAY_RATE))
    return thread.base_weight * decay_factor
```

**Configuration:**
```json
{
  "settings": {
    "weight_decay_rate": 0.02,  # 2% per day
    "weight_decay_min": 0.1,    # Never below 10%
    "weight_decay_enabled": true
  }
}
```

**Behavior:**
- Applied at injection time (not stored)
- Threads accessed recently get full weight
- Old threads fade naturally
- Reactivation restores weight

---

### 5. Batch Operations

**Goal:** Perform multiple operations in a single tool call.

**New MCP Tools:**

#### `ai_merge_batch(operations)`
```python
ai_merge_batch(operations=[
    {"survivor": "thread_a", "absorbed": "thread_b"},
    {"survivor": "thread_c", "absorbed": "thread_d"},
])
# Returns: summary of all merges
```

#### `ai_rename_batch(operations)`
```python
ai_rename_batch(operations=[
    {"thread_id": "thread_a", "new_title": "Title A"},
    {"thread_id": "thread_b", "new_title": "Title B"},
])
# Returns: summary of all renames
```

**Implementation:**
```python
def ai_merge_batch(operations):
    results = []
    for op in operations:
        try:
            result = merge(op["survivor"], op["absorbed"])
            results.append({"status": "ok", **op})
        except Exception as e:
            results.append({"status": "error", "error": str(e), **op})
    return format_batch_results(results)
```

---

## Configuration Schema

New settings added to `config.json`:

```json
{
  "version": "5.2.0",
  "settings": {
    "thread_mode": "normal",
    "active_threads_limit": 50,

    "auto_optimization": {
      "auto_merge_enabled": true,
      "auto_merge_threshold": 0.90,

      "dedup_enabled": true,
      "dedup_threshold": 0.85,

      "proactive_compact_enabled": true,
      "proactive_compact_threshold": 0.80,

      "weight_decay_enabled": true,
      "weight_decay_rate": 0.02,
      "weight_decay_min": 0.1
    }
  }
}
```

---

## Implementation Priority

| Feature | Difficulty | Impact | Priority |
|---------|------------|--------|----------|
| Batch operations | Easy | High (UX) | P1 |
| Proactive compression | Easy | High | P1 |
| Auto-merge | Medium | High | P2 |
| Weight decay | Medium | Medium | P2 |
| Deduplication | Complex | Very High | P3 |

**Phase 1 (v5.2.0):** Batch ops + Proactive compression
**Phase 2 (v5.2.1):** Auto-merge + Weight decay
**Phase 3 (v5.3.0):** Deduplication at creation

---

## Migration

No database migration required. New settings use defaults if not present.

---

## Testing

1. **Batch operations:** Create 5 threads, rename all with single call
2. **Proactive compression:** Fill to >80% pressure, verify auto-compact triggers
3. **Auto-merge:** Create 3 very similar threads, verify auto-merge
4. **Weight decay:** Create old thread, verify reduced effective weight
5. **Deduplication:** Create similar content twice, verify enrichment

---

## Changelog

- **v5.2.0** - Initial spec based on KratOs feedback
